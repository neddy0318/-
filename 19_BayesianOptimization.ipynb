{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization\n",
    "\n",
    "## 1. 개요\n",
    "\n",
    "&nbsp;&nbsp; 1)베이지안 최적화란?\n",
    "\n",
    "&nbsp;&nbsp;&nbsp; -베이지안 최적화에서 \"베이지안\"이라는 용어는 베이즈 정리를 기반으로 하기 때문에 붙은 것입니다. 베이즈 정리는 새로운 데이터에 따라 기존 믿음을 업데이트하는 방법을 제시합니다. 베이지안 최적화에서는 관측된 데이터를 기반으로 사전 확률을 사후 확률로 업데이트하는 과정을 통해, 함수의 분포를 개선하고 최적 하이퍼파라미터를 탐색합니다\n",
    "\n",
    "&nbsp;&nbsp; 2)정리\n",
    "\n",
    "&nbsp;&nbsp;&nbsp; - 베이지안 최적화는 하이퍼파라미터를 최적화하기 위한 방법 중 하나로, 미지의 목적함수를 학습하여 이를 전역 최적해로 만드는 파라미터를 찾는데 사용합니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp; - 복잡하고 노이즈가 많거나 평가 비용이 많이 드는 경우에 유용하며, 특히 하이퍼파라미터 튜닝에 많이 사용합니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp; - 그리드서치가 시간이 너무 오래걸리고, 랜덤서치가 정확도가 다소 떨어질 수 있다는 단점이 있는 것에 비해 효율적으로 최적값을 찾아낸다는 장점이 있습니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp; - 그렇기 때문에 가능한 최소의 시도로 최적의 답을 찾아야 할 경우에, 혹은 개별 시도가 너무 많은 시간가 자원을 소모할 때 활용하기 좋습니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp; - 베이지안 최적화의 핵심은 확률 기반이라는 것과, 사전 정보를 최적값 탐색에 반영한다는 것입니다. 그렇다면 사전 정보를 어떻게 학습하고 자동적으로 업데이트를 할까요? \n",
    "\n",
    "## 2. 주요 개념\n",
    "\n",
    "&nbsp;&nbsp; 1)대체 모델(Surrogate Model)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp; - 실제 모델에 대한 대체 모델로, 미지의 목적 함수를 대신하여 함수의 값을 빠르고 저렴하게 예측합니다. 이를 통해 베이지안 최적화는 평가 비용이 높은 실제 모델을 반복적으로 실행하는 대신, 대체 모델을 사용해 더 효율적으로 최적의 하이퍼파라미터를 탐색할 수 있습니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp; - 대체 모델을 학습하는 데에는 주로 가우시안 프로세스(Gaussian Process, GP)를 사용하며, 그 외에 랜덤 포레스트나 트리 파라젠을 활용하기도 합니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; (1)가우시안 프로세스 (Gaussian Process, GP): 가장 널리 사용되는 대체 모델로, 함수의 출력을 정규 분포로 모델링합니다. GP는 함수의 불확실성을 함께 제공하므로, 다음 샘플링할 지점을 결정하는 데 유용합니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; (2)랜덤 포레스트 (Random Forest): 랜덤 포레스트는 가우시안 프로세스보다 빠르게 훈련될 수 있지만, 불확실성 추정에서는 덜 효과적일 수 있습니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; (3)심층 신경망 (Deep Neural Networks): 최근에는 심층 신경망을 대체 모델로 사용하는 경우도 많습니다. 특히 함수의 복잡성이 높거나 데이터가 많을 때 유용합니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; (4)서포트 벡터 머신 (Support Vector Machines, SVM): 함수의 출력을 분류하거나 회귀하는 데 사용할 수 있는 모델입니다. 비선형적인 함수에 대해 잘 작동할 수 있습니다.\n",
    "\n",
    "\n",
    "&nbsp;&nbsp; 2)획득 함수(Acquisition Function)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp; - 획득 함수는 대체 모델의 예측을 바탕으로, 다음에 샘플링할 지점을 결정하는 기준을 제공합니다. 주요 획득 함수는 다음과 같습니다:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; (1)예상 개선 (Expected Improvement, EI): 현재까지의 최적값과 비교하여, 다음 샘플링 지점에서 얻을 수 있는 개선 정도를 기대하는 값입니다. 이 함수는 최적화 과정에서 유망한 지점을 탐색하는 데 도움을 줍니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; (2)확률적 개선 (Probability of Improvement, PI): 현재까지의 최적값보다 나은 결과를 얻을 확률을 최대화하는 지점을 선택합니다. PI는 보수적인 탐색을 선호할 수 있습니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; (3)톱-엑스 (Upper Confidence Bound, UCB): 현재 모델의 예측과 불확실성을 결합하여 다음 샘플링 지점을 결정합니다. UCB는 탐색과 착취 사이의 균형을 조절할 수 있는 파라미터를 가지고 있습니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; (4)볼츠만 탐색 (Boltzmann Exploration): 확률적으로 각 지점을 선택하는 방법으로, 높은 불확실성을 가진 지점을 선택할 확률이 높아집니다.\n",
    "\n",
    "\n",
    "&nbsp;&nbsp; #추가설명 : 가우시안 프로세스\n",
    "\n",
    "&nbsp;&nbsp;&nbsp; -가우시안 프로세스(Gaussian Process, GP)는 연속적인 함수의 분포를 모델링하는 비모수적 베이지안 접근법으로, 관측된 데이터 포인트들 간의 상관관계를 기반으로 합니다. 이는 주어진 입력 값에서 함수의 출력 값을 확률적으로 예측하며, 예측의 불확실성을 포함한 신뢰 구간을 제공합니다. 주요 개념은 다음과 같습니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; (1)가우시안 분포(Gaussian Distribution): GP는 다변수 가우시안 분포를 일반화한 것입니다. 가우시안 분포는 평균과 분산으로 정의되는 단변수 확률 분포로, GP는 이를 확장하여 함수 전체의 분포를 다룹니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; (2)평균 함수(Mean Function): GP의 평균 함수는 입력 값에 대한 함수의 기대 값을 나타냅니다. 일반적으로 0으로 설정하는 경우가 많습니다.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; (3)공분산 함수(Covariance Function) 또는 커널(Kernel): 공분산 함수는 두 입력 값 간의 상관관계를 나타내며, GP의 핵심 요소입니다. 주로 사용되는 커널로는 Radial Basis Function (RBF) 커널, Matern 커널 등이 있습니다. RBF 커널은 다음과 같이 정의됩니다(여기서 l은 길이 척도 파라미터입니다):\n",
    "$$\n",
    "k(x, x') = \\exp \\left( -\\frac{\\|x - x'\\|^2}{2l^2} \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "![](https://velog.velcdn.com/images/gangjoo/post/ca5bbad6-1389-43f3-9ede-5cab8dfa0959/image.gif)\n",
    "\n",
    "&nbsp;&nbsp;  *출처: https://commons.wikimedia.org/wiki/File:GpParBayesAnimationSmall.gif*\n",
    "\n",
    "## 3. 방식\n",
    "\n",
    "&nbsp;&nbsp; - 대체 모델과 획득함수를 기반으로하여, 베이지안 최적화는 기본적으로 미지의 함수가 반환하는 값의 최소 또는 최댓값을 만드는 최적해를 짧은 반복을 통해 찾아냅니다.\n",
    "\n",
    "&nbsp;&nbsp; - 새로운 데이터를 입력 받을 때 최적 함수를 예측하는 사후 모델을 개선해나가며 최적함수를 도출합니다.\n",
    "\n",
    "&nbsp;&nbsp; - 대체 모델은 획득함수로부터 최적 입력 값을 추천 받은 뒤 이를 기반으로 최적 함수 모델을 개선합니다.\n",
    "\n",
    "&nbsp;&nbsp; - 획득 함수는 개선된 데체 모델을 기반으로 다시 최적 입력 값을 계산합니다.\n",
    "\n",
    "## 4. 절차\n",
    "\n",
    "&nbsp;&nbsp; 1)처음에는 하이퍼 파라미터들을 랜덤 샘플링하여 성능 결과를 관측합니다.\n",
    "\n",
    "&nbsp;&nbsp; 2)위의 관측된 값을 기반으로 대체 모델이 최적 함수를 추정합니다.\n",
    "\n",
    "&nbsp;&nbsp; 3)획득 함수에서 다음으로 관측할 하이퍼 파라미터를 추출합니다.\n",
    "\n",
    "&nbsp;&nbsp; 4)해당 하이퍼 파라미터로 관측된 값을 기반으로 대체 모델이 다시 최적 함수를 추정합니다.\n",
    "\n",
    "## 5. 참고자료\n",
    "\n",
    "&nbsp;&nbsp; https://data-scientist-brian-kim.tistory.com/88\n",
    "\n",
    "&nbsp;&nbsp; https://peimsam.tistory.com/716\n",
    "\n",
    "&nbsp;&nbsp; https://velog.io/@gangjoo/ML-%EB%B6%84%EB%A5%98-%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88-%EC%B5%9C%EC%A0%81%ED%99%94-Bayesian-Optimization\n",
    "\n",
    "## 6. 코드 실습\n",
    "\n",
    "&nbsp;&nbsp; - 참고자료 : https://dsdingdong.tistory.com/61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# -10 ~ 10까지 1간격을 가지는 입력 변수 x, -15 ~ 15까지 1간격을 가지는 입력 변수 y 설정\n",
    "search_space = {'x':hp.quniform('x', -10, 10, 1), 'y':hp.quniform('y', -15, 15, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# 목적 함수를 생성. 변수값과 변수 검색 공간을 가지는 딕셔너리를 인자로 받고, 특정값을 반환\n",
    "def objective_func(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    retval = x**2 -20*y # retval = x**2-20*y로 계산된 값을 반환하게 설정한 이유는 예제를 위해서 임의로 만든것\n",
    "\n",
    "    return retval\n",
    "# hyperopt에서 목적 함수의 반환값은 권장하는 양식이 다음과 같음\n",
    "# return {'loss':retval, 'status':STATUS_OK}\n",
    "# return retval 만 해도 잘 반환됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 626.63trial/s, best loss: -224.0]\n",
      "best: {'x': np.float64(-4.0), 'y': np.float64(12.0)}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "import numpy as np\n",
    "\n",
    "# 입력값 및 해당 입력값의 목적 함수 반환값 결과를 저장할 Trials 객체값 생성\n",
    "trial_val = Trials()\n",
    "\n",
    "# 목적 함수의 반환값이 최솟값을 가지는 최적 입력값을 5번의 입력값 시도(max_evals=5)로 찾아냄\n",
    "best_01 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=5,\n",
    "              trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "print('best:', best_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 724.36trial/s, best loss: -296.0]\n",
      "best: {'x': np.float64(2.0), 'y': np.float64(15.0)}\n"
     ]
    }
   ],
   "source": [
    "trial_val = Trials()\n",
    "\n",
    "# max_evals를 20회로 늘려서 재테스트\n",
    "best_02 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=20,\n",
    "              trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "print('best:', best_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'loss': -64.0, 'status': 'ok'}, {'loss': -184.0, 'status': 'ok'}, {'loss': 56.0, 'status': 'ok'}, {'loss': -224.0, 'status': 'ok'}, {'loss': 61.0, 'status': 'ok'}, {'loss': -296.0, 'status': 'ok'}, {'loss': -40.0, 'status': 'ok'}, {'loss': 281.0, 'status': 'ok'}, {'loss': 64.0, 'status': 'ok'}, {'loss': 100.0, 'status': 'ok'}, {'loss': 60.0, 'status': 'ok'}, {'loss': -39.0, 'status': 'ok'}, {'loss': 1.0, 'status': 'ok'}, {'loss': -164.0, 'status': 'ok'}, {'loss': 21.0, 'status': 'ok'}, {'loss': -56.0, 'status': 'ok'}, {'loss': 284.0, 'status': 'ok'}, {'loss': 176.0, 'status': 'ok'}, {'loss': -171.0, 'status': 'ok'}, {'loss': 0.0, 'status': 'ok'}]\n"
     ]
    }
   ],
   "source": [
    "# result: 리스트 내부의 개별 원소는 {'loss':함수 반환값, 'status':반환 상태값}와 같은 딕셔너리\n",
    "print(trial_val.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [np.float64(-6.0), np.float64(-4.0), np.float64(4.0), np.float64(-4.0), np.float64(9.0), np.float64(2.0), np.float64(10.0), np.float64(-9.0), np.float64(-8.0), np.float64(-0.0), np.float64(-0.0), np.float64(1.0), np.float64(9.0), np.float64(6.0), np.float64(9.0), np.float64(2.0), np.float64(-2.0), np.float64(-4.0), np.float64(7.0), np.float64(-0.0)], 'y': [np.float64(5.0), np.float64(10.0), np.float64(-2.0), np.float64(12.0), np.float64(1.0), np.float64(15.0), np.float64(7.0), np.float64(-10.0), np.float64(0.0), np.float64(-5.0), np.float64(-3.0), np.float64(2.0), np.float64(4.0), np.float64(10.0), np.float64(3.0), np.float64(3.0), np.float64(-14.0), np.float64(-8.0), np.float64(11.0), np.float64(-0.0)]}\n"
     ]
    }
   ],
   "source": [
    "# vals: {'입력변수명':개별 수행 시마다 입력된 값의 리스트}와 같은 형태\n",
    "print(trial_val.vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x     y  losses\n",
       "0   -6.0   5.0   -64.0\n",
       "1   -4.0  10.0  -184.0\n",
       "2    4.0  -2.0    56.0\n",
       "3   -4.0  12.0  -224.0\n",
       "4    9.0   1.0    61.0\n",
       "5    2.0  15.0  -296.0\n",
       "6   10.0   7.0   -40.0\n",
       "7   -9.0 -10.0   281.0\n",
       "8   -8.0   0.0    64.0\n",
       "9   -0.0  -5.0   100.0\n",
       "10  -0.0  -3.0    60.0\n",
       "11   1.0   2.0   -39.0\n",
       "12   9.0   4.0     1.0\n",
       "13   6.0  10.0  -164.0\n",
       "14   9.0   3.0    21.0\n",
       "15   2.0   3.0   -56.0\n",
       "16  -2.0 -14.0   284.0\n",
       "17  -4.0  -8.0   176.0\n",
       "18   7.0  11.0  -171.0\n",
       "19  -0.0  -0.0     0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# result에서 loss 키값에 해당하는 value를 추출하여 list로 생성\n",
    "losses = [loss_dict['loss'] for loss_dict in trial_val.results]\n",
    "\n",
    "# DataFrame으로 생성\n",
    "result_df = pd.DataFrame({'x':trial_val.vals['x'], 'y':trial_val.vals['y'], 'losses':losses})\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
